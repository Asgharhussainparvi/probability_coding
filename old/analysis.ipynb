{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from itertools import count\n",
    "import operator\n",
    "import math\n",
    "EPSILON = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(word):\n",
    "    \"\"\"\n",
    "    Standardizes words by:\n",
    "    1. Converting to lowercase\n",
    "    2. Removing punctuation\n",
    "    3. Keeping only alphabetic characters\n",
    "    \"\"\"\n",
    "    standard = word.lower().strip()\n",
    "    # remove punctuation\n",
    "    standard = ''.join([i for i in standard if i.isalpha()])\n",
    "    return standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_stop(word):\n",
    "    \"\"\"\n",
    "    Removes common words that don't help in analysis\n",
    "    \"\"\"\n",
    "    stop_words = ['to', 'i', 'the', 'and', 'of']\n",
    "    return word in stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_word_to_count_map(wordMap, word):\n",
    "    \"\"\"\n",
    "    Updates word count in dictionary:\n",
    "    1. Skips stop words\n",
    "    2. Initializes count if new word\n",
    "    3. Increments count if existing word\n",
    "    \"\"\"\n",
    "    if is_stop(word):\n",
    "        return\n",
    "    if not word in wordMap:\n",
    "        wordMap[word] = 0\n",
    "    wordMap[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_word_count_map(fileName):\n",
    "    \"\"\"\n",
    "    Reads a file and counts word frequencies:\n",
    "    1. Opens file\n",
    "    2. Splits into words\n",
    "    3. Standardizes each word\n",
    "    4. Counts occurrences\n",
    "    Returns: (wordMap, total word count)\n",
    "    \"\"\"\n",
    "    wordMap = {}\n",
    "    nWords = 0\n",
    "    with open(fileName ,encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            words = line.split(' ')\n",
    "            for word in words:\n",
    "                word = standardize(word)\n",
    "                add_word_to_count_map(wordMap, word)\n",
    "                nWords+= 1\n",
    "    \n",
    "    \n",
    "    return wordMap, nWords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_prob(word_prob_map, word):\n",
    "    \"\"\"\n",
    "    Gets probability of a word:\n",
    "    Returns probability if word exists, EPSILON if not\n",
    "    \"\"\"\n",
    "    if word in word_prob_map:\n",
    "        return word_prob_map[word]\n",
    "    return EPSILON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_term_doc_given_author(prob_map, counts):\n",
    "    \"\"\"\n",
    "    How likely is the document, given the counts of words in the doc\n",
    "    and the authors prob_map\n",
    "    \"\"\"\n",
    "    # prob = 1\n",
    "    # for word, c_i in counts.items():\n",
    "    #     p_word = get_word_prob(prob_map, word)\n",
    "    #     prob *= p_word ** c_i\n",
    "    #     print(word, c_i, prob)\n",
    "    # return prob\n",
    "    prob = 0\n",
    "    for word, c_i in counts.items():\n",
    "        p_word = get_word_prob(prob_map, word)\n",
    "        prob += math.log(p_word) ** c_i\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_word_prob_map(fileName):\n",
    "    \"\"\"\n",
    "    Calculates word probabilities:\n",
    "    1. Counts word frequencies\n",
    "    2. Converts counts to probabilities\n",
    "    Returns: word probability dictionary\n",
    "    \"\"\"\n",
    "    wordMap, nWords = make_word_count_map(fileName)\n",
    "    # print(fileName)\n",
    "    # print(\"----------------------------\")\n",
    "    # print(wordMap)\n",
    "    # print(\"----------------------------\")\n",
    "    # print(nWords)\n",
    "    # print(\"----------------------------\")\n",
    "    probabilityMap = {}\n",
    "    for word in wordMap:\n",
    "        count = wordMap[word]\n",
    "        p = float(count) / nWords\n",
    "        probabilityMap[word] = p\n",
    "    return probabilityMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Real Term\t 0.0\n",
      "Ai Term\t 0.0\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Calculate all the ps and qs\n",
    "    # Eg hamiltonWordProb['congress'] = 0.005\n",
    "    # hamilton_word_prob['piech'] = 0.0\n",
    "    # hamilton_word_prob['the'] = 0.001\n",
    "\n",
    "    real_word_prob = make_word_prob_map('Real.txt')\n",
    "    ai_word_prob = make_word_prob_map('Ai.txt')\n",
    "\n",
    "    \n",
    "\n",
    "    # Get the word count of the unknown document\n",
    "    # Eg unknown_doc_count['congress'] = 5\n",
    "    test_doc_count, n_words = make_word_count_map('Test.txt')\n",
    "\n",
    "    # print(\"hamilton['congress']\\t\", hamilton_word_prob['congress'])\n",
    "    # print(\"madison['congress']\\t\",  madison_word_prob['congress'])\n",
    "    # print(\"doc_count['congress']\\t\", unknown_doc_count['congress'])\n",
    "    # print(\"n_words\", n_words)\n",
    "\n",
    "    real_term = calc_term_doc_given_author(real_word_prob, test_doc_count)\n",
    "    print('---'*10)\n",
    "    ai_term = calc_term_doc_given_author(ai_word_prob, test_doc_count)\n",
    "    # print(\"If term greater than zero than it is REAL otherwise AI\")\n",
    "    print(\"Real Term\\t\", real_term)\n",
    "    print(\"Ai Term\\t\", ai_term)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
