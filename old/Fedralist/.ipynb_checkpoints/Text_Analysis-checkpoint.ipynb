{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamilton['congress']\t 0.0011592117360195067\n",
      "madison['congress']\t 0.00016016229779509903\n",
      "doc_count['congress']\t 1\n",
      "n_words 2172\n",
      "------------------------------\n",
      "Hamilton Term\t 1\n",
      "Madison Term\t 1\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from itertools import count\n",
    "import operator\n",
    "import math\n",
    "\n",
    "EPSILON = 0.000001\n",
    "\n",
    "def main():\n",
    "    # Calculate all the ps and qs\n",
    "    # Eg hamiltonWordProb['congress'] = 0.005\n",
    "    # hamilton_word_prob['piech'] = 0.0\n",
    "    # hamilton_word_prob['the'] = 0.001\n",
    "\n",
    "    hamilton_word_prob = make_word_prob_map('hamilton.txt')\n",
    "    madison_word_prob = make_word_prob_map('madison.txt')\n",
    "\n",
    "    \n",
    "\n",
    "    # Get the word count of the unknown document\n",
    "    # Eg unknown_doc_count['congress'] = 5\n",
    "    unknown_doc_count, n_words = make_word_count_map('unknown.txt')\n",
    "\n",
    "    print(\"hamilton['congress']\\t\", hamilton_word_prob['congress'])\n",
    "    print(\"madison['congress']\\t\",  madison_word_prob['congress'])\n",
    "    print(\"doc_count['congress']\\t\", unknown_doc_count['congress'])\n",
    "    print(\"n_words\", n_words)\n",
    "\n",
    "    hamilton_term = calc_term_doc_given_author(hamilton_word_prob, unknown_doc_count)\n",
    "    print('---'*10)\n",
    "    madison_term = calc_term_doc_given_author(madison_word_prob, unknown_doc_count)\n",
    "    print(\"Hamilton Term\\t\", hamilton_term)\n",
    "    print(\"Madison Term\\t\",madison_term)\n",
    "\n",
    "def calc_term_doc_given_author(prob_map, counts):\n",
    "    \"\"\"\n",
    "    How likely is the document, given the counts of words in the doc\n",
    "    and the authors prob_map\n",
    "    \"\"\"\n",
    "    prob = 1\n",
    "    return prob\n",
    "\n",
    "\n",
    "# If a word is in a probability dictionary, return its probability\n",
    "# otherwise, return epsilon\n",
    "def get_word_prob(word_prob_map, word):\n",
    "    if word in word_prob_map:\n",
    "        return word_prob_map[word]\n",
    "    return EPSILON\n",
    "\n",
    "# From a file name, approximate the probability of a word\n",
    "# being generated from the same distribution as the file.\n",
    "# Assume that each word is produced independently, regardless\n",
    "# of order.\n",
    "def make_word_prob_map(fileName):\n",
    "    wordMap, nWords = make_word_count_map(fileName)\n",
    "    probabilityMap = {}\n",
    "    for word in wordMap:\n",
    "        count = wordMap[word]\n",
    "        p = float(count) / nWords\n",
    "        probabilityMap[word] = p\n",
    "    return probabilityMap\n",
    "\n",
    "# From a file name, count the number of times each word exists\n",
    "# in that file. Return the result as a map (aka a dictionary)\n",
    "def make_word_count_map(fileName):\n",
    "    wordMap = {}\n",
    "    nWords = 0\n",
    "    with open(fileName ,encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            words = line.split(' ')\n",
    "            for word in words:\n",
    "                word = standardize(word)\n",
    "                add_word_to_count_map(wordMap, word)\n",
    "                nWords+= 1\n",
    "    return wordMap, nWords\n",
    "\n",
    "# Add a word to a count map. Makes sure not to crash if the\n",
    "# word has not been seen before.\n",
    "def add_word_to_count_map(wordMap, word):\n",
    "    if is_stop(word):\n",
    "        return\n",
    "    if not word in wordMap:\n",
    "        wordMap[word] = 0\n",
    "    wordMap[word] += 1\n",
    "\n",
    "# Standardizes a word. For now, we are just going to make it\n",
    "# lower case.\n",
    "def standardize(word):\n",
    "    standard = word.lower().strip()\n",
    "    # remove punctuation\n",
    "    standard = ''.join([i for i in standard if i.isalpha()])\n",
    "    return standard\n",
    "\n",
    "def is_stop(word):\n",
    "    stop_words = ['to', 'i', 'the', 'and', 'of']\n",
    "    return word in stop_words\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamilton['congress']\t 0.0011592117360195067\n",
      "madison['congress']\t 0.00016016229779509903\n",
      "doc_count['congress']\t 1\n",
      "n_words 2172\n",
      "people 7 2.183281419899546e-19\n",
      "state 8 2.7281394801783755e-40\n",
      "new 3 4.70462106704184e-49\n",
      "york 1 1.6925126755157116e-52\n",
      "shall 1 2.435562070534661e-55\n",
      "here 2 3.5024444376044617e-63\n",
      "perhaps 3 4.9146842996601816e-73\n",
      "be 51 4.960426722501693e-165\n",
      "reminded 1 4.960426722501693e-171\n",
      "a 48 2.2070799408351614e-250\n",
      "current 1 2.6466961756027838e-254\n",
      "observation 2 2.6466961756027837e-266\n",
      "that 24 3.077901723387e-312\n",
      "where 6 0.0\n",
      "annual 6 0.0\n",
      "elections 14 0.0\n",
      "end 1 0.0\n",
      "tyranny 2 0.0\n",
      "begins 1 0.0\n",
      " 2 0.0\n",
      "if 7 0.0\n",
      "it 18 0.0\n",
      "true 4 0.0\n",
      "as 22 0.0\n",
      "has 8 0.0\n",
      "often 2 0.0\n",
      "been 7 0.0\n",
      "remarked 1 0.0\n",
      "sayings 1 0.0\n",
      "which 23 0.0\n",
      "become 5 0.0\n",
      "proverbial 2 0.0\n",
      "are 19 0.0\n",
      "generally 1 0.0\n",
      "founded 2 0.0\n",
      "in 45 0.0\n",
      "reason 3 0.0\n",
      "is 28 0.0\n",
      "not 19 0.0\n",
      "less 6 0.0\n",
      "when 1 0.0\n",
      "once 1 0.0\n",
      "established 6 0.0\n",
      "they 12 0.0\n",
      "applied 1 0.0\n",
      "cases 3 0.0\n",
      "them 7 0.0\n",
      "does 4 0.0\n",
      "extend 1 0.0\n",
      "need 1 0.0\n",
      "look 1 0.0\n",
      "for 21 0.0\n",
      "proof 1 0.0\n",
      "beyond 2 0.0\n",
      "case 4 0.0\n",
      "before 2 0.0\n",
      "us 2 0.0\n",
      "what 4 0.0\n",
      "on 8 0.0\n",
      "this 15 0.0\n",
      "no 10 0.0\n",
      "man 2 0.0\n",
      "will 25 0.0\n",
      "subject 5 0.0\n",
      "himself 1 0.0\n",
      "ridicule 1 0.0\n",
      "pretending 1 0.0\n",
      "any 6 0.0\n",
      "natural 2 0.0\n",
      "connection 2 0.0\n",
      "subsists 1 0.0\n",
      "between 7 0.0\n",
      "sun 1 0.0\n",
      "or 12 0.0\n",
      "seasons 1 0.0\n",
      "period 7 0.0\n",
      "within 4 0.0\n",
      "human 1 0.0\n",
      "virtue 1 0.0\n",
      "can 13 0.0\n",
      "bear 3 0.0\n",
      "temptations 1 0.0\n",
      "power 4 0.0\n",
      "happily 1 0.0\n",
      "mankind 1 0.0\n",
      "liberty 5 0.0\n",
      "respect 1 0.0\n",
      "confined 1 0.0\n",
      "single 5 0.0\n",
      "point 2 0.0\n",
      "time 5 0.0\n",
      "but 11 0.0\n",
      "lies 1 0.0\n",
      "extremes 1 0.0\n",
      "afford 1 0.0\n",
      "sufficient 2 0.0\n",
      "latitude 1 0.0\n",
      "all 9 0.0\n",
      "variations 1 0.0\n",
      "may 7 0.0\n",
      "required 1 0.0\n",
      "by 31 0.0\n",
      "various 1 0.0\n",
      "situations 2 0.0\n",
      "circumstances 4 0.0\n",
      "civil 3 0.0\n",
      "society 1 0.0\n",
      "election 4 0.0\n",
      "magistrates 2 0.0\n",
      "might 3 0.0\n",
      "were 4 0.0\n",
      "found 1 0.0\n",
      "expedient 2 0.0\n",
      "some 12 0.0\n",
      "instances 2 0.0\n",
      "actually 2 0.0\n",
      "daily 1 0.0\n",
      "weekly 1 0.0\n",
      "monthly 1 0.0\n",
      "well 4 0.0\n",
      "require 2 0.0\n",
      "deviation 1 0.0\n",
      "from 11 0.0\n",
      "rule 1 0.0\n",
      "one 7 0.0\n",
      "side 2 0.0\n",
      "why 1 0.0\n",
      "also 4 0.0\n",
      "other 14 0.0\n",
      "turning 1 0.0\n",
      "our 4 0.0\n",
      "attention 5 0.0\n",
      "periods 3 0.0\n",
      "among 3 0.0\n",
      "ourselves 1 0.0\n",
      "most 8 0.0\n",
      "numerous 2 0.0\n",
      "branches 3 0.0\n",
      "legislatures 1 0.0\n",
      "we 4 0.0\n",
      "find 1 0.0\n",
      "means 5 0.0\n",
      "coinciding 1 0.0\n",
      "more 10 0.0\n",
      "instance 1 0.0\n",
      "than 7 0.0\n",
      "connecticut 2 0.0\n",
      "rhode 2 0.0\n",
      "island 2 0.0\n",
      "halfyearly 1 0.0\n",
      "states 16 0.0\n",
      "south 3 0.0\n",
      "carolina 3 0.0\n",
      "excepted 1 0.0\n",
      "biennial 4 0.0\n",
      "proposed 1 0.0\n",
      "federal 9 0.0\n",
      "government 15 0.0\n",
      "difference 1 0.0\n",
      "four 2 0.0\n",
      "longest 1 0.0\n",
      "shortest 1 0.0\n",
      "yet 3 0.0\n",
      "would 6 0.0\n",
      "easy 1 0.0\n",
      "show 1 0.0\n",
      "better 2 0.0\n",
      "governed 2 0.0\n",
      "enjoys 1 0.0\n",
      "greater 3 0.0\n",
      "share 1 0.0\n",
      "rational 1 0.0\n",
      "either 2 0.0\n",
      "these 10 0.0\n",
      "distinguished 2 0.0\n",
      "respects 2 0.0\n",
      "causes 1 0.0\n",
      "whose 1 0.0\n",
      "different 7 0.0\n",
      "both 3 0.0\n",
      "searching 1 0.0\n",
      "grounds 1 0.0\n",
      "doctrine 2 0.0\n",
      "discover 1 0.0\n",
      "wholly 1 0.0\n",
      "inapplicable 1 0.0\n",
      "important 1 0.0\n",
      "distinction 1 0.0\n",
      "so 4 0.0\n",
      "understood 2 0.0\n",
      "america 2 0.0\n",
      "constitution 6 0.0\n",
      "unalterable 1 0.0\n",
      "law 2 0.0\n",
      "alterable 1 0.0\n",
      "seems 1 0.0\n",
      "have 7 0.0\n",
      "little 3 0.0\n",
      "observed 1 0.0\n",
      "country 1 0.0\n",
      "wherever 1 0.0\n",
      "supreme 1 0.0\n",
      "legislation 7 0.0\n",
      "resided 1 0.0\n",
      "supposed 1 0.0\n",
      "reside 1 0.0\n",
      "full 1 0.0\n",
      "change 1 0.0\n",
      "form 3 0.0\n",
      "even 4 0.0\n",
      "great 3 0.0\n",
      "britain 1 0.0\n",
      "principles 1 0.0\n",
      "political 1 0.0\n",
      "discussed 1 0.0\n",
      "hear 1 0.0\n",
      "rights 1 0.0\n",
      "maintained 1 0.0\n",
      "authority 2 0.0\n",
      "parliament 1 0.0\n",
      "transcendent 1 0.0\n",
      "uncontrollable 1 0.0\n",
      "with 11 0.0\n",
      "regard 2 0.0\n",
      "ordinary 3 0.0\n",
      "objects 5 0.0\n",
      "legislative 7 0.0\n",
      "provision 1 0.0\n",
      "accordingly 1 0.0\n",
      "several 4 0.0\n",
      "changed 2 0.0\n",
      "acts 1 0.0\n",
      "fundamental 1 0.0\n",
      "articles 1 0.0\n",
      "particular 3 0.0\n",
      "occasions 1 0.0\n",
      "last 1 0.0\n",
      "occasion 1 0.0\n",
      "only 4 0.0\n",
      "introduced 1 0.0\n",
      "septennial 1 0.0\n",
      "place 3 0.0\n",
      "triennial 1 0.0\n",
      "same 2 0.0\n",
      "act 1 0.0\n",
      "continued 1 0.0\n",
      "themselves 2 0.0\n",
      "years 3 0.0\n",
      "term 1 0.0\n",
      "elected 2 0.0\n",
      "an 6 0.0\n",
      "dangerous 1 0.0\n",
      "practices 1 0.0\n",
      "produced 1 0.0\n",
      "very 9 0.0\n",
      "alarm 1 0.0\n",
      "votaries 1 0.0\n",
      "free 1 0.0\n",
      "frequency 1 0.0\n",
      "cornerstone 1 0.0\n",
      "led 1 0.0\n",
      "seek 1 0.0\n",
      "security 4 0.0\n",
      "against 2 0.0\n",
      "danger 2 0.0\n",
      "exposed 1 0.0\n",
      "paramount 2 0.0\n",
      "existed 1 0.0\n",
      "could 2 0.0\n",
      "obtained 2 0.0\n",
      "constitutional 1 0.0\n",
      "similar 2 0.0\n",
      "united 3 0.0\n",
      "was 4 0.0\n",
      "attempted 1 0.0\n",
      "therefore 2 0.0\n",
      "sought 1 0.0\n",
      "admit 1 0.0\n",
      "selecting 1 0.0\n",
      "appealing 1 0.0\n",
      "simple 3 0.0\n",
      "familiar 2 0.0\n",
      "portion 4 0.0\n",
      "standard 1 0.0\n",
      "measuring 1 0.0\n",
      "innovations 2 0.0\n",
      "fixing 1 0.0\n",
      "national 1 0.0\n",
      "sentiment 1 0.0\n",
      "uniting 1 0.0\n",
      "patriotic 1 0.0\n",
      "exertions 1 0.0\n",
      "applicable 2 0.0\n",
      "year 7 0.0\n",
      "hence 2 0.0\n",
      "inculcated 1 0.0\n",
      "laudable 1 0.0\n",
      "zeal 1 0.0\n",
      "erect 1 0.0\n",
      "barrier 1 0.0\n",
      "gradual 1 0.0\n",
      "unlimited 1 0.0\n",
      "advance 1 0.0\n",
      "towards 1 0.0\n",
      "calculated 1 0.0\n",
      "distance 2 0.0\n",
      "departure 1 0.0\n",
      "fixed 2 0.0\n",
      "necessity 1 0.0\n",
      "there 2 0.0\n",
      "applying 1 0.0\n",
      "limited 2 0.0\n",
      "who 4 0.0\n",
      "pretend 1 0.0\n",
      "liberties 1 0.0\n",
      "secure 1 0.0\n",
      "under 1 0.0\n",
      "unalterably 1 0.0\n",
      "such 4 0.0\n",
      "those 5 0.0\n",
      "nation 1 0.0\n",
      "frequent 3 0.0\n",
      "alterations 1 0.0\n",
      "second 1 0.0\n",
      "question 4 0.0\n",
      "stated 1 0.0\n",
      "whether 1 0.0\n",
      "necessary 3 0.0\n",
      "useful 2 0.0\n",
      "propriety 1 0.0\n",
      "answering 1 0.0\n",
      "affirmative 1 0.0\n",
      "appear 1 0.0\n",
      "obvious 1 0.0\n",
      "considerations 3 0.0\n",
      "competent 1 0.0\n",
      "legislator 1 0.0\n",
      "add 1 0.0\n",
      "upright 1 0.0\n",
      "intention 1 0.0\n",
      "sound 1 0.0\n",
      "judgment 1 0.0\n",
      "certain 1 0.0\n",
      "degree 2 0.0\n",
      "knowledge 13 0.0\n",
      "subjects 1 0.0\n",
      "he 3 0.0\n",
      "legislate 1 0.0\n",
      "part 3 0.0\n",
      "acquired 3 0.0\n",
      "information 6 0.0\n",
      "lie 2 0.0\n",
      "compass 2 0.0\n",
      "men 2 0.0\n",
      "private 1 0.0\n",
      "public 6 0.0\n",
      "stations 1 0.0\n",
      "another 1 0.0\n",
      "attained 2 0.0\n",
      "at 2 0.0\n",
      "least 1 0.0\n",
      "thoroughly 2 0.0\n",
      "actual 2 0.0\n",
      "experience 2 0.0\n",
      "station 1 0.0\n",
      "requires 1 0.0\n",
      "use 2 0.0\n",
      "service 6 0.0\n",
      "ought 6 0.0\n",
      "proportion 3 0.0\n",
      "extent 1 0.0\n",
      "practical 2 0.0\n",
      "requisite 4 0.0\n",
      "due 2 0.0\n",
      "performance 1 0.0\n",
      "branch 2 0.0\n",
      "seen 2 0.0\n",
      "then 1 0.0\n",
      "put 1 0.0\n",
      "into 2 0.0\n",
      "two 2 0.0\n",
      "statement 1 0.0\n",
      "suggests 1 0.0\n",
      "answer 2 0.0\n",
      "given 2 0.0\n",
      "relates 1 0.0\n",
      "existing 2 0.0\n",
      "laws 7 0.0\n",
      "uniform 4 0.0\n",
      "throughout 2 0.0\n",
      "citizens 2 0.0\n",
      "conversant 1 0.0\n",
      "general 2 0.0\n",
      "affairs 9 0.0\n",
      "small 1 0.0\n",
      "diversified 2 0.0\n",
      "occupy 1 0.0\n",
      "much 3 0.0\n",
      "conversation 2 0.0\n",
      "every 4 0.0\n",
      "class 1 0.0\n",
      "theatre 1 0.0\n",
      "presents 1 0.0\n",
      "scene 1 0.0\n",
      "far 3 0.0\n",
      "being 1 0.0\n",
      "vary 1 0.0\n",
      "whilst 1 0.0\n",
      "union 2 0.0\n",
      "spread 1 0.0\n",
      "extensive 2 0.0\n",
      "region 1 0.0\n",
      "extremely 1 0.0\n",
      "t 1 0.0\n",
      "e 1 0.0\n",
      "local 2 0.0\n",
      "connected 1 0.0\n",
      "difficulty 2 0.0\n",
      "correctly 1 0.0\n",
      "learnt 1 0.0\n",
      "central 1 0.0\n",
      "councils 1 0.0\n",
      "brought 1 0.0\n",
      "representatives 6 0.0\n",
      "empire 1 0.0\n",
      "possessed 1 0.0\n",
      "members 7 0.0\n",
      "each 3 0.0\n",
      "how 4 0.0\n",
      "foreign 3 0.0\n",
      "trade 2 0.0\n",
      "properly 1 0.0\n",
      "regulated 2 0.0\n",
      "without 3 0.0\n",
      "acquaintance 1 0.0\n",
      "commerce 2 0.0\n",
      "ports 1 0.0\n",
      "usages 1 0.0\n",
      "regulatious 1 0.0\n",
      "duly 2 0.0\n",
      "their 4 0.0\n",
      "relative 1 0.0\n",
      "taxes 1 0.0\n",
      "judiciously 1 0.0\n",
      "imposed 1 0.0\n",
      "effectually 1 0.0\n",
      "collected 1 0.0\n",
      "accommodated 1 0.0\n",
      "relating 1 0.0\n",
      "regulations 1 0.0\n",
      "militia 1 0.0\n",
      "provided 1 0.0\n",
      "many 2 0.0\n",
      "internal 1 0.0\n",
      "principal 1 0.0\n",
      "suggest 1 0.0\n",
      "forcibly 1 0.0\n",
      "acquire 1 0.0\n",
      "interior 1 0.0\n",
      "proportional 1 0.0\n",
      "difficulties 1 0.0\n",
      "degrees 1 0.0\n",
      "diminished 1 0.0\n",
      "laborious 1 0.0\n",
      "task 1 0.0\n",
      "proper 2 0.0\n",
      "inauguration 1 0.0\n",
      "primeval 1 0.0\n",
      "formation 1 0.0\n",
      "code 1 0.0\n",
      "improvements 2 0.0\n",
      "first 1 0.0\n",
      "draughts 1 0.0\n",
      "easier 1 0.0\n",
      "fewer 1 0.0\n",
      "past 1 0.0\n",
      "transactions 1 0.0\n",
      "ready 1 0.0\n",
      "accurate 1 0.0\n",
      "source 1 0.0\n",
      "curiosity 1 0.0\n",
      "large 2 0.0\n",
      "increased 1 0.0\n",
      "intercourse 1 0.0\n",
      "contribute 2 0.0\n",
      "diffuse 1 0.0\n",
      "mutual 1 0.0\n",
      "again 1 0.0\n",
      "assimilation 1 0.0\n",
      "manners 1 0.0\n",
      "abatements 1 0.0\n",
      "business 3 0.0\n",
      "must 2 0.0\n",
      "continue 1 0.0\n",
      "exceed 1 0.0\n",
      "novelty 1 0.0\n",
      "justify 1 0.0\n",
      "longer 1 0.0\n",
      "assigned 1 0.0\n",
      "transact 1 0.0\n",
      "belongs 1 0.0\n",
      "acquirements 1 0.0\n",
      "representative 1 0.0\n",
      "mentioned 1 0.0\n",
      "regulating 1 0.0\n",
      "own 1 0.0\n",
      "acquainted 1 0.0\n",
      "treaties 1 0.0\n",
      "nations 3 0.0\n",
      "commercial 1 0.0\n",
      "policy 1 0.0\n",
      "altogether 1 0.0\n",
      "ignorant 1 0.0\n",
      "object 1 0.0\n",
      "municipal 1 0.0\n",
      "submitted 1 0.0\n",
      "although 1 0.0\n",
      "house 3 0.0\n",
      "immediately 1 0.0\n",
      "participate 1 0.0\n",
      "negotiations 1 0.0\n",
      "arrangements 2 0.0\n",
      "frequently 1 0.0\n",
      "deserve 1 0.0\n",
      "course 3 0.0\n",
      "sometimes 1 0.0\n",
      "demand 1 0.0\n",
      "sanction 1 0.0\n",
      "cooperation 1 0.0\n",
      "doubt 1 0.0\n",
      "mans 1 0.0\n",
      "closet 1 0.0\n",
      "derived 1 0.0\n",
      "sources 1 0.0\n",
      "best 1 0.0\n",
      "effect 2 0.0\n",
      "during 1 0.0\n",
      "legislature 2 0.0\n",
      "importance 1 0.0\n",
      "unworthy 1 0.0\n",
      "notice 1 0.0\n",
      "obliged 1 0.0\n",
      "travel 1 0.0\n",
      "rendered 1 0.0\n",
      "circumstance 1 0.0\n",
      "serious 2 0.0\n",
      "objections 1 0.0\n",
      "fit 1 0.0\n",
      "extended 1 0.0\n",
      "argument 1 0.0\n",
      "drawn 1 0.0\n",
      "delegates 1 0.0\n",
      "congress 1 0.0\n",
      "annually 1 0.0\n",
      "reelection 1 0.0\n",
      "considered 1 0.0\n",
      "assemblies 2 0.0\n",
      "almost 1 0.0\n",
      "matter 2 0.0\n",
      "principle 1 0.0\n",
      "few 1 0.0\n",
      "happens 1 0.0\n",
      "possess 1 0.0\n",
      "superior 1 0.0\n",
      "talents 1 0.0\n",
      "reelections 1 0.0\n",
      "long 1 0.0\n",
      "standing 1 0.0\n",
      "masters 1 0.0\n",
      "unwilling 1 0.0\n",
      "avail 1 0.0\n",
      "advantages 2 0.0\n",
      "bulk 1 0.0\n",
      "apt 1 0.0\n",
      "fall 1 0.0\n",
      "snares 1 0.0\n",
      "laid 1 0.0\n",
      "remark 1 0.0\n",
      "relation 1 0.0\n",
      "subsist 1 0.0\n",
      "senate 1 0.0\n",
      "inconvenience 1 0.0\n",
      "mingled 1 0.0\n",
      "hold 1 0.0\n",
      "session 1 0.0\n",
      "spurious 1 0.0\n",
      "cannot 1 0.0\n",
      "investigated 1 0.0\n",
      "annulled 1 0.0\n",
      "decision 1 0.0\n",
      "its 2 0.0\n",
      "return 1 0.0\n",
      "unlawful 2 0.0\n",
      "irregular 2 0.0\n",
      "member 2 0.0\n",
      "takes 1 0.0\n",
      "his 3 0.0\n",
      "seat 3 0.0\n",
      "sure 1 0.0\n",
      "holding 1 0.0\n",
      "purposes 1 0.0\n",
      "pernicious 1 0.0\n",
      "encouragement 1 0.0\n",
      "obtaining 2 0.0\n",
      "returns 2 0.0\n",
      "practice 1 0.0\n",
      "abuse 1 0.0\n",
      "particularly 1 0.0\n",
      "distant 1 0.0\n",
      "necessarily 1 0.0\n",
      "judge 1 0.0\n",
      "qualifications 1 0.0\n",
      "whatever 1 0.0\n",
      "suggested 1 0.0\n",
      "simplifying 1 0.0\n",
      "accelerating 1 0.0\n",
      "process 1 0.0\n",
      "disputed 1 0.0\n",
      "unavoidably 1 0.0\n",
      "elapse 1 0.0\n",
      "illegitimate 1 0.0\n",
      "dispossessed 1 0.0\n",
      "prospect 1 0.0\n",
      "event 1 0.0\n",
      "check 1 0.0\n",
      "unfair 1 0.0\n",
      "illicit 1 0.0\n",
      "taken 1 0.0\n",
      "together 1 0.0\n",
      "warrant 1 0.0\n",
      "affirming 1 0.0\n",
      "safe 1 0.0\n",
      "------------------------------\n",
      "people 7 3.0763612651710167e-18\n",
      "state 8 6.747117350978622e-39\n",
      "new 3 9.50808939735082e-48\n",
      "york 1 6.091349782083704e-51\n",
      "shall 1 3.252015259240672e-54\n",
      "here 2 2.317238074069326e-61\n",
      "perhaps 3 1.7323455637224388e-70\n",
      "be 51 2.3596798486696083e-155\n",
      "reminded 1 1.25977248874572e-159\n",
      "a 48 7.312482630218717e-240\n",
      "current 1 3.903946735475264e-244\n",
      "observation 2 1.7803358557069927e-251\n",
      "that 24 4.3548115515810424e-298\n",
      "where 6 3.42956167e-316\n",
      "annual 6 0.0\n",
      "elections 14 0.0\n",
      "end 1 0.0\n",
      "tyranny 2 0.0\n",
      "begins 1 0.0\n",
      " 2 0.0\n",
      "if 7 0.0\n",
      "it 18 0.0\n",
      "true 4 0.0\n",
      "as 22 0.0\n",
      "has 8 0.0\n",
      "often 2 0.0\n",
      "been 7 0.0\n",
      "remarked 1 0.0\n",
      "sayings 1 0.0\n",
      "which 23 0.0\n",
      "become 5 0.0\n",
      "proverbial 2 0.0\n",
      "are 19 0.0\n",
      "generally 1 0.0\n",
      "founded 2 0.0\n",
      "in 45 0.0\n",
      "reason 3 0.0\n",
      "is 28 0.0\n",
      "not 19 0.0\n",
      "less 6 0.0\n",
      "when 1 0.0\n",
      "once 1 0.0\n",
      "established 6 0.0\n",
      "they 12 0.0\n",
      "applied 1 0.0\n",
      "cases 3 0.0\n",
      "them 7 0.0\n",
      "does 4 0.0\n",
      "extend 1 0.0\n",
      "need 1 0.0\n",
      "look 1 0.0\n",
      "for 21 0.0\n",
      "proof 1 0.0\n",
      "beyond 2 0.0\n",
      "case 4 0.0\n",
      "before 2 0.0\n",
      "us 2 0.0\n",
      "what 4 0.0\n",
      "on 8 0.0\n",
      "this 15 0.0\n",
      "no 10 0.0\n",
      "man 2 0.0\n",
      "will 25 0.0\n",
      "subject 5 0.0\n",
      "himself 1 0.0\n",
      "ridicule 1 0.0\n",
      "pretending 1 0.0\n",
      "any 6 0.0\n",
      "natural 2 0.0\n",
      "connection 2 0.0\n",
      "subsists 1 0.0\n",
      "between 7 0.0\n",
      "sun 1 0.0\n",
      "or 12 0.0\n",
      "seasons 1 0.0\n",
      "period 7 0.0\n",
      "within 4 0.0\n",
      "human 1 0.0\n",
      "virtue 1 0.0\n",
      "can 13 0.0\n",
      "bear 3 0.0\n",
      "temptations 1 0.0\n",
      "power 4 0.0\n",
      "happily 1 0.0\n",
      "mankind 1 0.0\n",
      "liberty 5 0.0\n",
      "respect 1 0.0\n",
      "confined 1 0.0\n",
      "single 5 0.0\n",
      "point 2 0.0\n",
      "time 5 0.0\n",
      "but 11 0.0\n",
      "lies 1 0.0\n",
      "extremes 1 0.0\n",
      "afford 1 0.0\n",
      "sufficient 2 0.0\n",
      "latitude 1 0.0\n",
      "all 9 0.0\n",
      "variations 1 0.0\n",
      "may 7 0.0\n",
      "required 1 0.0\n",
      "by 31 0.0\n",
      "various 1 0.0\n",
      "situations 2 0.0\n",
      "circumstances 4 0.0\n",
      "civil 3 0.0\n",
      "society 1 0.0\n",
      "election 4 0.0\n",
      "magistrates 2 0.0\n",
      "might 3 0.0\n",
      "were 4 0.0\n",
      "found 1 0.0\n",
      "expedient 2 0.0\n",
      "some 12 0.0\n",
      "instances 2 0.0\n",
      "actually 2 0.0\n",
      "daily 1 0.0\n",
      "weekly 1 0.0\n",
      "monthly 1 0.0\n",
      "well 4 0.0\n",
      "require 2 0.0\n",
      "deviation 1 0.0\n",
      "from 11 0.0\n",
      "rule 1 0.0\n",
      "one 7 0.0\n",
      "side 2 0.0\n",
      "why 1 0.0\n",
      "also 4 0.0\n",
      "other 14 0.0\n",
      "turning 1 0.0\n",
      "our 4 0.0\n",
      "attention 5 0.0\n",
      "periods 3 0.0\n",
      "among 3 0.0\n",
      "ourselves 1 0.0\n",
      "most 8 0.0\n",
      "numerous 2 0.0\n",
      "branches 3 0.0\n",
      "legislatures 1 0.0\n",
      "we 4 0.0\n",
      "find 1 0.0\n",
      "means 5 0.0\n",
      "coinciding 1 0.0\n",
      "more 10 0.0\n",
      "instance 1 0.0\n",
      "than 7 0.0\n",
      "connecticut 2 0.0\n",
      "rhode 2 0.0\n",
      "island 2 0.0\n",
      "halfyearly 1 0.0\n",
      "states 16 0.0\n",
      "south 3 0.0\n",
      "carolina 3 0.0\n",
      "excepted 1 0.0\n",
      "biennial 4 0.0\n",
      "proposed 1 0.0\n",
      "federal 9 0.0\n",
      "government 15 0.0\n",
      "difference 1 0.0\n",
      "four 2 0.0\n",
      "longest 1 0.0\n",
      "shortest 1 0.0\n",
      "yet 3 0.0\n",
      "would 6 0.0\n",
      "easy 1 0.0\n",
      "show 1 0.0\n",
      "better 2 0.0\n",
      "governed 2 0.0\n",
      "enjoys 1 0.0\n",
      "greater 3 0.0\n",
      "share 1 0.0\n",
      "rational 1 0.0\n",
      "either 2 0.0\n",
      "these 10 0.0\n",
      "distinguished 2 0.0\n",
      "respects 2 0.0\n",
      "causes 1 0.0\n",
      "whose 1 0.0\n",
      "different 7 0.0\n",
      "both 3 0.0\n",
      "searching 1 0.0\n",
      "grounds 1 0.0\n",
      "doctrine 2 0.0\n",
      "discover 1 0.0\n",
      "wholly 1 0.0\n",
      "inapplicable 1 0.0\n",
      "important 1 0.0\n",
      "distinction 1 0.0\n",
      "so 4 0.0\n",
      "understood 2 0.0\n",
      "america 2 0.0\n",
      "constitution 6 0.0\n",
      "unalterable 1 0.0\n",
      "law 2 0.0\n",
      "alterable 1 0.0\n",
      "seems 1 0.0\n",
      "have 7 0.0\n",
      "little 3 0.0\n",
      "observed 1 0.0\n",
      "country 1 0.0\n",
      "wherever 1 0.0\n",
      "supreme 1 0.0\n",
      "legislation 7 0.0\n",
      "resided 1 0.0\n",
      "supposed 1 0.0\n",
      "reside 1 0.0\n",
      "full 1 0.0\n",
      "change 1 0.0\n",
      "form 3 0.0\n",
      "even 4 0.0\n",
      "great 3 0.0\n",
      "britain 1 0.0\n",
      "principles 1 0.0\n",
      "political 1 0.0\n",
      "discussed 1 0.0\n",
      "hear 1 0.0\n",
      "rights 1 0.0\n",
      "maintained 1 0.0\n",
      "authority 2 0.0\n",
      "parliament 1 0.0\n",
      "transcendent 1 0.0\n",
      "uncontrollable 1 0.0\n",
      "with 11 0.0\n",
      "regard 2 0.0\n",
      "ordinary 3 0.0\n",
      "objects 5 0.0\n",
      "legislative 7 0.0\n",
      "provision 1 0.0\n",
      "accordingly 1 0.0\n",
      "several 4 0.0\n",
      "changed 2 0.0\n",
      "acts 1 0.0\n",
      "fundamental 1 0.0\n",
      "articles 1 0.0\n",
      "particular 3 0.0\n",
      "occasions 1 0.0\n",
      "last 1 0.0\n",
      "occasion 1 0.0\n",
      "only 4 0.0\n",
      "introduced 1 0.0\n",
      "septennial 1 0.0\n",
      "place 3 0.0\n",
      "triennial 1 0.0\n",
      "same 2 0.0\n",
      "act 1 0.0\n",
      "continued 1 0.0\n",
      "themselves 2 0.0\n",
      "years 3 0.0\n",
      "term 1 0.0\n",
      "elected 2 0.0\n",
      "an 6 0.0\n",
      "dangerous 1 0.0\n",
      "practices 1 0.0\n",
      "produced 1 0.0\n",
      "very 9 0.0\n",
      "alarm 1 0.0\n",
      "votaries 1 0.0\n",
      "free 1 0.0\n",
      "frequency 1 0.0\n",
      "cornerstone 1 0.0\n",
      "led 1 0.0\n",
      "seek 1 0.0\n",
      "security 4 0.0\n",
      "against 2 0.0\n",
      "danger 2 0.0\n",
      "exposed 1 0.0\n",
      "paramount 2 0.0\n",
      "existed 1 0.0\n",
      "could 2 0.0\n",
      "obtained 2 0.0\n",
      "constitutional 1 0.0\n",
      "similar 2 0.0\n",
      "united 3 0.0\n",
      "was 4 0.0\n",
      "attempted 1 0.0\n",
      "therefore 2 0.0\n",
      "sought 1 0.0\n",
      "admit 1 0.0\n",
      "selecting 1 0.0\n",
      "appealing 1 0.0\n",
      "simple 3 0.0\n",
      "familiar 2 0.0\n",
      "portion 4 0.0\n",
      "standard 1 0.0\n",
      "measuring 1 0.0\n",
      "innovations 2 0.0\n",
      "fixing 1 0.0\n",
      "national 1 0.0\n",
      "sentiment 1 0.0\n",
      "uniting 1 0.0\n",
      "patriotic 1 0.0\n",
      "exertions 1 0.0\n",
      "applicable 2 0.0\n",
      "year 7 0.0\n",
      "hence 2 0.0\n",
      "inculcated 1 0.0\n",
      "laudable 1 0.0\n",
      "zeal 1 0.0\n",
      "erect 1 0.0\n",
      "barrier 1 0.0\n",
      "gradual 1 0.0\n",
      "unlimited 1 0.0\n",
      "advance 1 0.0\n",
      "towards 1 0.0\n",
      "calculated 1 0.0\n",
      "distance 2 0.0\n",
      "departure 1 0.0\n",
      "fixed 2 0.0\n",
      "necessity 1 0.0\n",
      "there 2 0.0\n",
      "applying 1 0.0\n",
      "limited 2 0.0\n",
      "who 4 0.0\n",
      "pretend 1 0.0\n",
      "liberties 1 0.0\n",
      "secure 1 0.0\n",
      "under 1 0.0\n",
      "unalterably 1 0.0\n",
      "such 4 0.0\n",
      "those 5 0.0\n",
      "nation 1 0.0\n",
      "frequent 3 0.0\n",
      "alterations 1 0.0\n",
      "second 1 0.0\n",
      "question 4 0.0\n",
      "stated 1 0.0\n",
      "whether 1 0.0\n",
      "necessary 3 0.0\n",
      "useful 2 0.0\n",
      "propriety 1 0.0\n",
      "answering 1 0.0\n",
      "affirmative 1 0.0\n",
      "appear 1 0.0\n",
      "obvious 1 0.0\n",
      "considerations 3 0.0\n",
      "competent 1 0.0\n",
      "legislator 1 0.0\n",
      "add 1 0.0\n",
      "upright 1 0.0\n",
      "intention 1 0.0\n",
      "sound 1 0.0\n",
      "judgment 1 0.0\n",
      "certain 1 0.0\n",
      "degree 2 0.0\n",
      "knowledge 13 0.0\n",
      "subjects 1 0.0\n",
      "he 3 0.0\n",
      "legislate 1 0.0\n",
      "part 3 0.0\n",
      "acquired 3 0.0\n",
      "information 6 0.0\n",
      "lie 2 0.0\n",
      "compass 2 0.0\n",
      "men 2 0.0\n",
      "private 1 0.0\n",
      "public 6 0.0\n",
      "stations 1 0.0\n",
      "another 1 0.0\n",
      "attained 2 0.0\n",
      "at 2 0.0\n",
      "least 1 0.0\n",
      "thoroughly 2 0.0\n",
      "actual 2 0.0\n",
      "experience 2 0.0\n",
      "station 1 0.0\n",
      "requires 1 0.0\n",
      "use 2 0.0\n",
      "service 6 0.0\n",
      "ought 6 0.0\n",
      "proportion 3 0.0\n",
      "extent 1 0.0\n",
      "practical 2 0.0\n",
      "requisite 4 0.0\n",
      "due 2 0.0\n",
      "performance 1 0.0\n",
      "branch 2 0.0\n",
      "seen 2 0.0\n",
      "then 1 0.0\n",
      "put 1 0.0\n",
      "into 2 0.0\n",
      "two 2 0.0\n",
      "statement 1 0.0\n",
      "suggests 1 0.0\n",
      "answer 2 0.0\n",
      "given 2 0.0\n",
      "relates 1 0.0\n",
      "existing 2 0.0\n",
      "laws 7 0.0\n",
      "uniform 4 0.0\n",
      "throughout 2 0.0\n",
      "citizens 2 0.0\n",
      "conversant 1 0.0\n",
      "general 2 0.0\n",
      "affairs 9 0.0\n",
      "small 1 0.0\n",
      "diversified 2 0.0\n",
      "occupy 1 0.0\n",
      "much 3 0.0\n",
      "conversation 2 0.0\n",
      "every 4 0.0\n",
      "class 1 0.0\n",
      "theatre 1 0.0\n",
      "presents 1 0.0\n",
      "scene 1 0.0\n",
      "far 3 0.0\n",
      "being 1 0.0\n",
      "vary 1 0.0\n",
      "whilst 1 0.0\n",
      "union 2 0.0\n",
      "spread 1 0.0\n",
      "extensive 2 0.0\n",
      "region 1 0.0\n",
      "extremely 1 0.0\n",
      "t 1 0.0\n",
      "e 1 0.0\n",
      "local 2 0.0\n",
      "connected 1 0.0\n",
      "difficulty 2 0.0\n",
      "correctly 1 0.0\n",
      "learnt 1 0.0\n",
      "central 1 0.0\n",
      "councils 1 0.0\n",
      "brought 1 0.0\n",
      "representatives 6 0.0\n",
      "empire 1 0.0\n",
      "possessed 1 0.0\n",
      "members 7 0.0\n",
      "each 3 0.0\n",
      "how 4 0.0\n",
      "foreign 3 0.0\n",
      "trade 2 0.0\n",
      "properly 1 0.0\n",
      "regulated 2 0.0\n",
      "without 3 0.0\n",
      "acquaintance 1 0.0\n",
      "commerce 2 0.0\n",
      "ports 1 0.0\n",
      "usages 1 0.0\n",
      "regulatious 1 0.0\n",
      "duly 2 0.0\n",
      "their 4 0.0\n",
      "relative 1 0.0\n",
      "taxes 1 0.0\n",
      "judiciously 1 0.0\n",
      "imposed 1 0.0\n",
      "effectually 1 0.0\n",
      "collected 1 0.0\n",
      "accommodated 1 0.0\n",
      "relating 1 0.0\n",
      "regulations 1 0.0\n",
      "militia 1 0.0\n",
      "provided 1 0.0\n",
      "many 2 0.0\n",
      "internal 1 0.0\n",
      "principal 1 0.0\n",
      "suggest 1 0.0\n",
      "forcibly 1 0.0\n",
      "acquire 1 0.0\n",
      "interior 1 0.0\n",
      "proportional 1 0.0\n",
      "difficulties 1 0.0\n",
      "degrees 1 0.0\n",
      "diminished 1 0.0\n",
      "laborious 1 0.0\n",
      "task 1 0.0\n",
      "proper 2 0.0\n",
      "inauguration 1 0.0\n",
      "primeval 1 0.0\n",
      "formation 1 0.0\n",
      "code 1 0.0\n",
      "improvements 2 0.0\n",
      "first 1 0.0\n",
      "draughts 1 0.0\n",
      "easier 1 0.0\n",
      "fewer 1 0.0\n",
      "past 1 0.0\n",
      "transactions 1 0.0\n",
      "ready 1 0.0\n",
      "accurate 1 0.0\n",
      "source 1 0.0\n",
      "curiosity 1 0.0\n",
      "large 2 0.0\n",
      "increased 1 0.0\n",
      "intercourse 1 0.0\n",
      "contribute 2 0.0\n",
      "diffuse 1 0.0\n",
      "mutual 1 0.0\n",
      "again 1 0.0\n",
      "assimilation 1 0.0\n",
      "manners 1 0.0\n",
      "abatements 1 0.0\n",
      "business 3 0.0\n",
      "must 2 0.0\n",
      "continue 1 0.0\n",
      "exceed 1 0.0\n",
      "novelty 1 0.0\n",
      "justify 1 0.0\n",
      "longer 1 0.0\n",
      "assigned 1 0.0\n",
      "transact 1 0.0\n",
      "belongs 1 0.0\n",
      "acquirements 1 0.0\n",
      "representative 1 0.0\n",
      "mentioned 1 0.0\n",
      "regulating 1 0.0\n",
      "own 1 0.0\n",
      "acquainted 1 0.0\n",
      "treaties 1 0.0\n",
      "nations 3 0.0\n",
      "commercial 1 0.0\n",
      "policy 1 0.0\n",
      "altogether 1 0.0\n",
      "ignorant 1 0.0\n",
      "object 1 0.0\n",
      "municipal 1 0.0\n",
      "submitted 1 0.0\n",
      "although 1 0.0\n",
      "house 3 0.0\n",
      "immediately 1 0.0\n",
      "participate 1 0.0\n",
      "negotiations 1 0.0\n",
      "arrangements 2 0.0\n",
      "frequently 1 0.0\n",
      "deserve 1 0.0\n",
      "course 3 0.0\n",
      "sometimes 1 0.0\n",
      "demand 1 0.0\n",
      "sanction 1 0.0\n",
      "cooperation 1 0.0\n",
      "doubt 1 0.0\n",
      "mans 1 0.0\n",
      "closet 1 0.0\n",
      "derived 1 0.0\n",
      "sources 1 0.0\n",
      "best 1 0.0\n",
      "effect 2 0.0\n",
      "during 1 0.0\n",
      "legislature 2 0.0\n",
      "importance 1 0.0\n",
      "unworthy 1 0.0\n",
      "notice 1 0.0\n",
      "obliged 1 0.0\n",
      "travel 1 0.0\n",
      "rendered 1 0.0\n",
      "circumstance 1 0.0\n",
      "serious 2 0.0\n",
      "objections 1 0.0\n",
      "fit 1 0.0\n",
      "extended 1 0.0\n",
      "argument 1 0.0\n",
      "drawn 1 0.0\n",
      "delegates 1 0.0\n",
      "congress 1 0.0\n",
      "annually 1 0.0\n",
      "reelection 1 0.0\n",
      "considered 1 0.0\n",
      "assemblies 2 0.0\n",
      "almost 1 0.0\n",
      "matter 2 0.0\n",
      "principle 1 0.0\n",
      "few 1 0.0\n",
      "happens 1 0.0\n",
      "possess 1 0.0\n",
      "superior 1 0.0\n",
      "talents 1 0.0\n",
      "reelections 1 0.0\n",
      "long 1 0.0\n",
      "standing 1 0.0\n",
      "masters 1 0.0\n",
      "unwilling 1 0.0\n",
      "avail 1 0.0\n",
      "advantages 2 0.0\n",
      "bulk 1 0.0\n",
      "apt 1 0.0\n",
      "fall 1 0.0\n",
      "snares 1 0.0\n",
      "laid 1 0.0\n",
      "remark 1 0.0\n",
      "relation 1 0.0\n",
      "subsist 1 0.0\n",
      "senate 1 0.0\n",
      "inconvenience 1 0.0\n",
      "mingled 1 0.0\n",
      "hold 1 0.0\n",
      "session 1 0.0\n",
      "spurious 1 0.0\n",
      "cannot 1 0.0\n",
      "investigated 1 0.0\n",
      "annulled 1 0.0\n",
      "decision 1 0.0\n",
      "its 2 0.0\n",
      "return 1 0.0\n",
      "unlawful 2 0.0\n",
      "irregular 2 0.0\n",
      "member 2 0.0\n",
      "takes 1 0.0\n",
      "his 3 0.0\n",
      "seat 3 0.0\n",
      "sure 1 0.0\n",
      "holding 1 0.0\n",
      "purposes 1 0.0\n",
      "pernicious 1 0.0\n",
      "encouragement 1 0.0\n",
      "obtaining 2 0.0\n",
      "returns 2 0.0\n",
      "practice 1 0.0\n",
      "abuse 1 0.0\n",
      "particularly 1 0.0\n",
      "distant 1 0.0\n",
      "necessarily 1 0.0\n",
      "judge 1 0.0\n",
      "qualifications 1 0.0\n",
      "whatever 1 0.0\n",
      "suggested 1 0.0\n",
      "simplifying 1 0.0\n",
      "accelerating 1 0.0\n",
      "process 1 0.0\n",
      "disputed 1 0.0\n",
      "unavoidably 1 0.0\n",
      "elapse 1 0.0\n",
      "illegitimate 1 0.0\n",
      "dispossessed 1 0.0\n",
      "prospect 1 0.0\n",
      "event 1 0.0\n",
      "check 1 0.0\n",
      "unfair 1 0.0\n",
      "illicit 1 0.0\n",
      "taken 1 0.0\n",
      "together 1 0.0\n",
      "warrant 1 0.0\n",
      "affirming 1 0.0\n",
      "safe 1 0.0\n",
      "Hamilton Term\t 0.0\n",
      "Madison Term\t 0.0\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from itertools import count\n",
    "import operator\n",
    "import math\n",
    "\n",
    "EPSILON = 0.000001\n",
    "\n",
    "def main():\n",
    "    # Calculate all the ps and qs\n",
    "    # Eg hamiltonWordProb['congress'] = 0.005\n",
    "    # hamilton_word_prob['piech'] = 0.0\n",
    "    # hamilton_word_prob['the'] = 0.001\n",
    "\n",
    "    hamilton_word_prob = make_word_prob_map('hamilton.txt')\n",
    "    madison_word_prob = make_word_prob_map('madison.txt')\n",
    "\n",
    "    \n",
    "\n",
    "    # Get the word count of the unknown document\n",
    "    # Eg unknown_doc_count['congress'] = 5\n",
    "    unknown_doc_count, n_words = make_word_count_map('unknown.txt')\n",
    "\n",
    "    print(\"hamilton['congress']\\t\", hamilton_word_prob['congress'])\n",
    "    print(\"madison['congress']\\t\",  madison_word_prob['congress'])\n",
    "    print(\"doc_count['congress']\\t\", unknown_doc_count['congress'])\n",
    "    print(\"n_words\", n_words)\n",
    "\n",
    "    hamilton_term = calc_term_doc_given_author(hamilton_word_prob, unknown_doc_count)\n",
    "    print('---'*10)\n",
    "    madison_term = calc_term_doc_given_author(madison_word_prob, unknown_doc_count)\n",
    "    print(\"Hamilton Term\\t\", hamilton_term)\n",
    "    print(\"Madison Term\\t\",madison_term)\n",
    "\n",
    "def calc_term_doc_given_author(prob_map, counts):\n",
    "    \"\"\"\n",
    "    How likely is the document, given the counts of words in the doc\n",
    "    and the authors prob_map\n",
    "    \"\"\"\n",
    "    prob = 1\n",
    "    for word, c_i in counts.items():\n",
    "        p_word = get_word_prob(prob_map, word)\n",
    "        prob *= p_word ** c_i\n",
    "        print(word, c_i, prob)\n",
    "    return prob\n",
    "    # prob = 0\n",
    "    # for word, c_i in counts.items():\n",
    "    #     p_word = get_word_prob(prob_map, word)\n",
    "    #     prob += math.log(p_word) * c_i\n",
    "    # return prob\n",
    "\n",
    "\n",
    "# If a word is in a probability dictionary, return its probability\n",
    "# otherwise, return epsilon\n",
    "def get_word_prob(word_prob_map, word):\n",
    "    if word in word_prob_map:\n",
    "        return word_prob_map[word]\n",
    "    return EPSILON\n",
    "\n",
    "# From a file name, approximate the probability of a word\n",
    "# being generated from the same distribution as the file.\n",
    "# Assume that each word is produced independently, regardless\n",
    "# of order.\n",
    "def make_word_prob_map(fileName):\n",
    "    wordMap, nWords = make_word_count_map(fileName)\n",
    "    probabilityMap = {}\n",
    "    for word in wordMap:\n",
    "        count = wordMap[word]\n",
    "        p = float(count) / nWords\n",
    "        probabilityMap[word] = p\n",
    "    return probabilityMap\n",
    "\n",
    "# From a file name, count the number of times each word exists\n",
    "# in that file. Return the result as a map (aka a dictionary)\n",
    "def make_word_count_map(fileName):\n",
    "    wordMap = {}\n",
    "    nWords = 0\n",
    "    with open(fileName ,encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            words = line.split(' ')\n",
    "            for word in words:\n",
    "                word = standardize(word)\n",
    "                add_word_to_count_map(wordMap, word)\n",
    "                nWords+= 1\n",
    "    return wordMap, nWords\n",
    "\n",
    "# Add a word to a count map. Makes sure not to crash if the\n",
    "# word has not been seen before.\n",
    "def add_word_to_count_map(wordMap, word):\n",
    "    if is_stop(word):\n",
    "        return\n",
    "    if not word in wordMap:\n",
    "        wordMap[word] = 0\n",
    "    wordMap[word] += 1\n",
    "\n",
    "# Standardizes a word. For now, we are just going to make it\n",
    "# lower case.\n",
    "def standardize(word):\n",
    "    standard = word.lower().strip()\n",
    "    # remove punctuation\n",
    "    standard = ''.join([i for i in standard if i.isalpha()])\n",
    "    return standard\n",
    "\n",
    "def is_stop(word):\n",
    "    stop_words = ['to', 'i', 'the', 'and', 'of']\n",
    "    return word in stop_words\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamilton['congress']\t 0.0011592117360195067\n",
      "madison['congress']\t 0.00016016229779509903\n",
      "doc_count['congress']\t 1\n",
      "n_words 2172\n",
      "log P(D|H)\t -14251.749082287015\n",
      "log P(D|M)\t -12898.137397440358\n",
      "diff\t -1353.6116848466572\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from itertools import count\n",
    "import operator\n",
    "import math\n",
    "\n",
    "EPSILON = 0.000001\n",
    "\n",
    "def main():\n",
    "    # Calculate all the ps and qs\n",
    "    # Eg hamiltonWordProb['congress'] = 0.005\n",
    "    # hamilton_word_prob['piech'] = 0.0\n",
    "    # hamilton_word_prob['the'] = 0.001\n",
    "\n",
    "    hamilton_word_prob = make_word_prob_map('hamilton.txt')\n",
    "    madison_word_prob = make_word_prob_map('madison.txt')\n",
    "\n",
    "    \n",
    "\n",
    "    # Get the word count of the unknown document\n",
    "    # Eg unknown_doc_count['congress'] = 5\n",
    "    unknown_doc_count, n_words = make_word_count_map('unknown.txt')\n",
    "\n",
    "    print(\"hamilton['congress']\\t\", hamilton_word_prob['congress'])\n",
    "    print(\"madison['congress']\\t\",  madison_word_prob['congress'])\n",
    "    print(\"doc_count['congress']\\t\", unknown_doc_count['congress'])\n",
    "    print(\"n_words\", n_words)\n",
    "\n",
    "    hamilton_term = calc_log_pr_doc_given_author(hamilton_word_prob, unknown_doc_count)\n",
    "    madison_term = calc_log_pr_doc_given_author(madison_word_prob, unknown_doc_count)\n",
    "    print(\"log P(D|H)\\t\", hamilton_term)\n",
    "    print(\"log P(D|M)\\t\",madison_term)\n",
    "\n",
    "    print('diff\\t', hamilton_term - madison_term)\n",
    "\n",
    "def calc_log_pr_doc_given_author(prob_map, counts):\n",
    "    \"\"\"\n",
    "    How likely is the document, given the counts of words in the doc\n",
    "    and the authors prob_map\n",
    "    \"\"\"\n",
    "    log_prob = math.log(1)\n",
    "    for word_i, c_i in counts.items():\n",
    "        p_i = get_word_prob(prob_map, word_i)\n",
    "        log_prob += c_i * math.log(p_i)\n",
    "    return log_prob\n",
    "\n",
    "\n",
    "def calcLogProbDoc(wordProbMap, countMap):\n",
    "    logProb = math.log(1)\n",
    "    for wordi in countMap:\n",
    "        ci = countMap[wordi]\n",
    "        pi = get_word_prob(wordProbMap, wordi)\n",
    "        logProb += ci * math.log(pi)\n",
    "    return logProb\n",
    "\n",
    "# If a word is in a probability dictionary, return its probability\n",
    "# otherwise, return epsilon\n",
    "def get_word_prob(word_prob_map, word):\n",
    "    if word in word_prob_map:\n",
    "        return word_prob_map[word]\n",
    "    return EPSILON\n",
    "\n",
    "# From a file name, approximate the probability of a word\n",
    "# being generated from the same distribution as the file.\n",
    "# Assume that each word is produced independently, regardless\n",
    "# of order.\n",
    "def make_word_prob_map(fileName):\n",
    "    wordMap, nWords = make_word_count_map(fileName)\n",
    "    probabilityMap = {}\n",
    "    for word in wordMap:\n",
    "        count = wordMap[word]\n",
    "        p = float(count) / nWords\n",
    "        probabilityMap[word] = p\n",
    "    return probabilityMap\n",
    "\n",
    "# From a file name, count the number of times each word exists\n",
    "# in that file. Return the result as a map (aka a dictionary)\n",
    "def make_word_count_map(fileName):\n",
    "    wordMap = {}\n",
    "    nWords = 0\n",
    "    with open(fileName , encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            words = line.split(' ')\n",
    "            for word in words:\n",
    "                word = standardize(word)\n",
    "                add_word_to_count_map(wordMap, word)\n",
    "                nWords+= 1\n",
    "    return wordMap, nWords\n",
    "\n",
    "# Add a word to a count map. Makes sure not to crash if the\n",
    "# word has not been seen before.\n",
    "def add_word_to_count_map(wordMap, word):\n",
    "    if not word in wordMap:\n",
    "        wordMap[word] = 0\n",
    "    wordMap[word] += 1\n",
    "\n",
    "# Standardizes a word. For now, we are just going to make it\n",
    "# lower case.\n",
    "def standardize(word):\n",
    "    standard = word.lower().strip()\n",
    "    # remove punctuation\n",
    "    standard = ''.join([i for i in standard if i.isalpha()])\n",
    "    return standard\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
