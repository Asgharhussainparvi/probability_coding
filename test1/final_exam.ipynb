{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set([\n",
    "    \"the\", \"and\", \"of\", \"to\", \"in\", \"a\", \"is\", \"that\", \"it\", \"with\", \"as\", \"for\", \"on\", \"are\", \"this\", \"by\", \"be\", \"have\", \"has\", \"or\", \"at\", \"an\", \"from\", \"their\", \"which\", \"these\", \"those\", \"was\", \"were\", \"been\", \"being\", \"through\", \"during\", \"its\", \"how\", \"into\", \"over\", \"across\", \"each\", \"more\", \"other\", \"such\", \"some\", \"any\", \"only\", \"also\", \"when\", \"than\", \"but\", \"not\", \"they\", \"we\", \"our\", \"us\", \"you\", \"your\", \"he\", \"she\", \"his\", \"her\", \"them\", \"its\", \"my\", \"mine\", \"your\", \"yours\", \"our\", \"ours\", \"their\", \"theirs\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        return f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = read_files('Physics.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]','',text)\n",
    "    words = text.split()\n",
    "    words_after_process = []\n",
    "    for word in words:\n",
    "       if word not in stop_words:\n",
    "           words_after_process.append(word)\n",
    "    return words_after_process\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(filename):\n",
    "    vocab = set()\n",
    "    f = read_files(filename)\n",
    "    words = process_text(f)\n",
    "    vocab.update(words)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies(filename,vocab):\n",
    "    word_counts = {}\n",
    "    text = read_files(filename)\n",
    "    words = process_text(text)\n",
    "    for word in vocab:\n",
    "        count = 0\n",
    "        if word in words:\n",
    "            count = words.count(word)\n",
    "            word_counts[word] = count\n",
    "        else:\n",
    "            return\n",
    "    return word_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_rel_prob(word_counts):\n",
    "    rel_freq = {}\n",
    "    for word,count in word_counts.items():\n",
    "        total_words = len(word)\n",
    "        rel_freq[word] = count/total_words\n",
    "    return rel_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_log_likelihood(filename,rel_prob):\n",
    "    text = read_files(filename)\n",
    "    file_words = process_text(text)\n",
    "    likelihoods = {}\n",
    "    rel_words = []\n",
    "    for word, prob in rel_prob.items():\n",
    "        likelihood = 0\n",
    "        rel_words.append(word)\n",
    "        for word in file_words:\n",
    "            if word in rel_words:\n",
    "                likelihood += log(rel_prob.get(prob,1e-6))\n",
    "                likelihoods[word] = likelihood\n",
    "    return likelihoods\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_file(filename,rel_probs):\n",
    "    for rel_prob in rel_probs:\n",
    "        likelihoods = calc_log_likelihood(filename,rel_prob)\n",
    "    return filename, max(likelihoods,key=likelihoods.get), likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['Physics.txt','Biology.txt','Economics.txt','Psychology.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_probs = []\n",
    "for file in files:\n",
    "    word_count = word_frequencies(file,build_vocab(file))\n",
    "    rel_prob = cal_rel_prob(word_count)\n",
    "    rel_probs.append(rel_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('unknown.txt', 'complex', {'complex': -13.815510557964274})"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_file('unknown.txt',rel_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('evolution',\n",
       " {'evolution': -13.815510557964274,\n",
       "  'shaped': -27.631021115928547,\n",
       "  'diversity': -41.44653167389282,\n",
       "  'species': -55.262042231857095,\n",
       "  'natural': -69.07755278982137,\n",
       "  'selection': -82.89306334778564,\n",
       "  'millions': -96.70857390574992,\n",
       "  'years': -110.52408446371419,\n",
       "  'cellular': -124.33959502167846,\n",
       "  'processes': -138.15510557964274,\n",
       "  'convert': -151.970616137607,\n",
       "  'nutrients': -165.78612669557128,\n",
       "  'energy': -179.60163725353556,\n",
       "  'complex': -193.41714781149983,\n",
       "  'biochemical': -207.2326583694641,\n",
       "  'pathways': -221.04816892742838,\n",
       "  'genetic': -234.86367948539265,\n",
       "  'information': -248.67919004335693,\n",
       "  'flows': -262.4947006013212,\n",
       "  'dna': -276.3102111592855,\n",
       "  'rna': -290.12572171724975,\n",
       "  'proteins': -303.941232275214,\n",
       "  'regulatory': -317.7567428331783,\n",
       "  'mechanisms': -331.57225339114257,\n",
       "  'controlling': -345.38776394910684,\n",
       "  'gene': -359.2032745070711,\n",
       "  'expression': -373.0187850650354,\n",
       "  'conservation': -386.83429562299966,\n",
       "  'efforts': -400.64980618096394,\n",
       "  'focus': -414.4653167389282,\n",
       "  'maintaining': -428.2808272968925,\n",
       "  'biodiversity': -442.09633785485676,\n",
       "  'ecosystems': -455.91184841282103,\n",
       "  'ensure': -469.7273589707853,\n",
       "  'longterm': -483.5428695287496,\n",
       "  'stability': -497.35838008671385})"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = word_frequencies('Physics.txt',build_vocab('Physics.txt'))\n",
    "rel_prob = cal_rel_prob(word_count)\n",
    "classify_file('unknown.txt',rel_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
