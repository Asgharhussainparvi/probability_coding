{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"the\", \"and\", \"of\"\"other\", \"such\", \"some\", \"any\", \"only\", \"also\",'it','a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filename):\n",
    "    f = open(filename,\"r\")\n",
    "    return f.read()\n",
    "\n",
    "def process_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]','',text)\n",
    "    words = text.split()\n",
    "    words_after_process = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "           words_after_process.append(word)\n",
    "    return words_after_process\n",
    "           \n",
    "    \n",
    "    \n",
    "def build_vocab(filename):\n",
    "    vocab = set()\n",
    "    f = load_file(filename)\n",
    "    words = process_text(f)\n",
    "    vocab.update(words)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies(filename,vocab):\n",
    "    word_counts = {}\n",
    "    text = load_file(filename)\n",
    "    words = process_text(text)\n",
    "    for word in vocab:\n",
    "        count = 0\n",
    "        if word in words:\n",
    "            count = words.count(word)\n",
    "            word_counts[word] = count\n",
    "        else:\n",
    "            return\n",
    "    return word_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_rel_prob(word_counts):\n",
    "    rel_freq = {}\n",
    "    for word,count in word_counts.items():\n",
    "        total_words = len(word)\n",
    "        rel_freq[word] = count/total_words\n",
    "    return rel_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'new': 1, 'alike': 1, 'interactions': 1, 'businesses': 1, 'artificial': 1, 'industries': 1, 'with': 1, 'intelligence': 1, 'transforming': 1, 'natural': 1, 'redefining': 1, 'technology': 1, 'in': 1, 'from': 1, 'selfdriving': 1, 'language': 1, 'machine': 1, 'unlocking': 1, 'to': 1, 'learning': 1, 'aipowered': 1, 'processing': 1, 'automation': 1, 'for': 1, 'chatbots': 1, 'cars': 1, 'humancomputer': 1, 'advancements': 1, 'possibilities': 1, 'consumers': 1, 'efficiency': 1, 'improving': 1, 'is': 2, 'rapidly': 1}\n",
      "{'new': 0.3333333333333333, 'alike': 0.2, 'interactions': 0.08333333333333333, 'businesses': 0.1, 'artificial': 0.1, 'industries': 0.1, 'with': 0.25, 'intelligence': 0.08333333333333333, 'transforming': 0.08333333333333333, 'natural': 0.14285714285714285, 'redefining': 0.1, 'technology': 0.1, 'in': 0.5, 'from': 0.25, 'selfdriving': 0.09090909090909091, 'language': 0.125, 'machine': 0.14285714285714285, 'unlocking': 0.1111111111111111, 'to': 0.5, 'learning': 0.125, 'aipowered': 0.1111111111111111, 'processing': 0.1, 'automation': 0.1, 'for': 0.3333333333333333, 'chatbots': 0.125, 'cars': 0.25, 'humancomputer': 0.07692307692307693, 'advancements': 0.08333333333333333, 'possibilities': 0.07692307692307693, 'consumers': 0.1111111111111111, 'efficiency': 0.1, 'improving': 0.1111111111111111, 'is': 1.0, 'rapidly': 0.14285714285714285}\n"
     ]
    }
   ],
   "source": [
    "text = load_file('technoloy.txt')\n",
    "text = process_text(text)\n",
    "vocab = build_vocab('technoloy.txt')\n",
    "freq = word_frequencies('technoloy.txt',vocab)\n",
    "print(freq)\n",
    "prob_tech = cal_rel_prob(freq)\n",
    "print(prob_tech)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'heart': 1, 'diet': 1, 'reduce': 1, 'mental': 1, 'chronic': 1, 'leading': 1, 'longer': 1, 'activity': 1, 'maintaining': 1, 'play': 1, 'in': 1, 'crucial': 1, 'can': 1, 'overall': 1, 'balanced': 1, 'active': 1, 'to': 1, 'show': 1, 'enhances': 1, 'physical': 2, 'health': 1, 'studies': 1, 'while': 1, 'more': 1, 'wellbeing': 1, 'diabetes': 1, 'as': 1, 'exercise': 1, 'risk': 1, 'proper': 1, 'even': 1, 'diseases': 1, 'role': 1, 'of': 1, 'life': 1, 'conditions': 1, 'nutrition': 1, 'that': 1, 'moderate': 1, 'regular': 1}\n",
      "{'heart': 0.2, 'diet': 0.25, 'reduce': 0.16666666666666666, 'mental': 0.16666666666666666, 'chronic': 0.14285714285714285, 'leading': 0.14285714285714285, 'longer': 0.16666666666666666, 'activity': 0.125, 'maintaining': 0.09090909090909091, 'play': 0.25, 'in': 0.5, 'crucial': 0.14285714285714285, 'can': 0.3333333333333333, 'overall': 0.14285714285714285, 'balanced': 0.125, 'active': 0.16666666666666666, 'to': 0.5, 'show': 0.25, 'enhances': 0.125, 'physical': 0.25, 'health': 0.16666666666666666, 'studies': 0.14285714285714285, 'while': 0.2, 'more': 0.25, 'wellbeing': 0.1111111111111111, 'diabetes': 0.125, 'as': 0.5, 'exercise': 0.125, 'risk': 0.25, 'proper': 0.16666666666666666, 'even': 0.25, 'diseases': 0.125, 'role': 0.25, 'of': 0.5, 'life': 0.25, 'conditions': 0.1, 'nutrition': 0.1111111111111111, 'that': 0.25, 'moderate': 0.125, 'regular': 0.14285714285714285}\n"
     ]
    }
   ],
   "source": [
    "text = load_file('health.txt')\n",
    "text = process_text(text)\n",
    "vocab = build_vocab('health.txt')\n",
    "freq = word_frequencies('health.txt',vocab)\n",
    "print(freq)\n",
    "prob_health = cal_rel_prob(freq)\n",
    "print(prob_health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'remain': 1, 'private': 1, 'divided': 1, 'intervention': 1, 'shape': 1, 'cuts': 1, 'on': 1, 'financial': 1, 'programs': 1, 'outcome': 1, 'discussions': 1, 'increased': 1, 'heated': 1, 'boost': 1, 'deregulation': 1, 'years': 1, 'policies': 1, 'advocate': 1, 'economic': 1, 'tax': 2, 'social': 1, 'in': 1, 'nations': 1, 'sector': 1, 'to': 3, 'over': 1, 'government': 1, 'others': 1, 'push': 1, 'will': 1, 'public': 1, 'while': 1, 'come': 1, 'for': 3, 'debate': 1, 'growth': 1, 'support': 1, 'landscape': 1, 'of': 1, 'these': 1, 'reforms': 1, 'lawmakers': 1, 'spending': 1}\n",
      "{'remain': 0.16666666666666666, 'private': 0.14285714285714285, 'divided': 0.14285714285714285, 'intervention': 0.08333333333333333, 'shape': 0.2, 'cuts': 0.25, 'on': 0.5, 'financial': 0.1111111111111111, 'programs': 0.125, 'outcome': 0.14285714285714285, 'discussions': 0.09090909090909091, 'increased': 0.1111111111111111, 'heated': 0.16666666666666666, 'boost': 0.2, 'deregulation': 0.08333333333333333, 'years': 0.2, 'policies': 0.125, 'advocate': 0.125, 'economic': 0.125, 'tax': 0.6666666666666666, 'social': 0.16666666666666666, 'in': 0.5, 'nations': 0.14285714285714285, 'sector': 0.16666666666666666, 'to': 1.5, 'over': 0.25, 'government': 0.1, 'others': 0.16666666666666666, 'push': 0.25, 'will': 0.25, 'public': 0.16666666666666666, 'while': 0.2, 'come': 0.25, 'for': 1.0, 'debate': 0.16666666666666666, 'growth': 0.16666666666666666, 'support': 0.14285714285714285, 'landscape': 0.1111111111111111, 'of': 0.5, 'these': 0.2, 'reforms': 0.14285714285714285, 'lawmakers': 0.1111111111111111, 'spending': 0.125}\n"
     ]
    }
   ],
   "source": [
    "text = load_file('politics.txt')\n",
    "text = process_text(text)\n",
    "vocab = build_vocab('politics.txt')\n",
    "freq = word_frequencies('politics.txt',vocab)\n",
    "print(freq)\n",
    "prob_polit = cal_rel_prob(freq)\n",
    "print(prob_polit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'compelling': 1, 'worldwide': 1, 'media': 1, 'with': 1, 'captivating': 1, 'power': 1, 'breaking': 1, 'blockbuster': 1, 'sparked': 1, 'social': 1, 'in': 1, 'has': 2, 'by': 1, 'latest': 1, 'box': 1, 'taken': 1, 'film': 1, 'conversations': 1, 'cast': 1, 'storyline': 1, 'movie': 1, 'across': 1, 'office': 1, 'visuals': 1, 'starstudded': 1, 'again': 1, 'storytelling': 1, 'cinema': 1, 'once': 1, 'storm': 1, 'breathtaking': 1, 'records': 1, 'proving': 1, 'audiences': 1, 'of': 1}\n",
      "{'compelling': 0.1, 'worldwide': 0.1111111111111111, 'media': 0.2, 'with': 0.25, 'captivating': 0.09090909090909091, 'power': 0.2, 'breaking': 0.125, 'blockbuster': 0.09090909090909091, 'sparked': 0.14285714285714285, 'social': 0.16666666666666666, 'in': 0.5, 'has': 0.6666666666666666, 'by': 0.5, 'latest': 0.16666666666666666, 'box': 0.3333333333333333, 'taken': 0.2, 'film': 0.25, 'conversations': 0.07692307692307693, 'cast': 0.25, 'storyline': 0.1111111111111111, 'movie': 0.2, 'across': 0.16666666666666666, 'office': 0.16666666666666666, 'visuals': 0.14285714285714285, 'starstudded': 0.09090909090909091, 'again': 0.2, 'storytelling': 0.08333333333333333, 'cinema': 0.16666666666666666, 'once': 0.25, 'storm': 0.2, 'breathtaking': 0.08333333333333333, 'records': 0.14285714285714285, 'proving': 0.14285714285714285, 'audiences': 0.1111111111111111, 'of': 0.5}\n"
     ]
    }
   ],
   "source": [
    "text = load_file('entertainement.txt')\n",
    "text = process_text(text)\n",
    "vocab = build_vocab('entertainement.txt')\n",
    "freq = word_frequencies('entertainement.txt',vocab)\n",
    "print(freq)\n",
    "prob_entr = cal_rel_prob(freq)\n",
    "print(prob_entr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihood(filename, domain_vocab):\n",
    "    text = load_file(filename)\n",
    "    unknown_words = process_text(text)\n",
    "    match_count = 0\n",
    "    for word in unknown_words:\n",
    "        if word in domain_vocab:\n",
    "            match_count += 1\n",
    "    return match_count / len(unknown_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3170731707317073\n",
      "0.04878048780487805\n",
      "0.07317073170731707\n",
      "0.024390243902439025\n"
     ]
    }
   ],
   "source": [
    "print(calculate_likelihood('unknown.txt', prob_health))\n",
    "print(calculate_likelihood('unknown.txt', prob_polit))\n",
    "print(calculate_likelihood('unknown.txt', prob_entr))\n",
    "print(calculate_likelihood('unknown.txt', prob_tech))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04878048780487805\n",
      "1.0\n",
      "0.0975609756097561\n",
      "0.04878048780487805\n"
     ]
    }
   ],
   "source": [
    "print(calculate_likelihood('unknown2.txt', prob_tech))\n",
    "print(calculate_likelihood('unknown2.txt', prob_health))\n",
    "print(calculate_likelihood('unknown2.txt', prob_polit))\n",
    "print(calculate_likelihood('unknown2.txt', prob_entr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
